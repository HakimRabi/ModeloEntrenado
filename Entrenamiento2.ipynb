{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c293fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40bc5b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc90df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6793abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b109c836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (0.12.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from seaborn) (3.7.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (22.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ed1691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (22.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: namex in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rich in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yasitcomputer\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab89c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                     fecha     consumo  flap_de_calidad  \\\n",
      "0  177760211  2019-02-01 00:00:00-0300  -51.381349                1   \n",
      "1  395102211  2019-02-01 00:00:00-0300 -171.906310                1   \n",
      "2  395684211  2019-02-01 00:00:00-0300   94.762790                1   \n",
      "3  397670211  2019-02-01 00:00:00-0300   47.114733                1   \n",
      "4  397693211  2019-02-01 00:00:00-0300   59.313975                1   \n",
      "\n",
      "   promedio_horas         nombre_interruptor   año  mes  dia  hora  \\\n",
      "0               4    AJAHUEL   110  H1     P  2019    2    1     0   \n",
      "1               4  BUIN      110  HT1    MTP  2019    2    1     0   \n",
      "2               4    BUIN      110  H2     P  2019    2    1     0   \n",
      "3               4    LOSALME   110  H1     P  2019    2    1     0   \n",
      "4               4    LOSALME   110  H3     P  2019    2    1     0   \n",
      "\n",
      "  sub_estacion  \n",
      "0      AJAHUEL  \n",
      "1         BUIN  \n",
      "2         BUIN  \n",
      "3      LOSALME  \n",
      "4      LOSALME  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2242968 entries, 0 to 2242967\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   id                  int64  \n",
      " 1   fecha               object \n",
      " 2   consumo             float64\n",
      " 3   flap_de_calidad     int64  \n",
      " 4   promedio_horas      int64  \n",
      " 5   nombre_interruptor  object \n",
      " 6   año                 int64  \n",
      " 7   mes                 int64  \n",
      " 8   dia                 int64  \n",
      " 9   hora                int64  \n",
      " 10  sub_estacion        object \n",
      "dtypes: float64(1), int64(7), object(3)\n",
      "memory usage: 188.2+ MB\n",
      "None\n",
      "                 id       consumo  flap_de_calidad  promedio_horas  \\\n",
      "count  2.242968e+06  2.242968e+06     2.242968e+06    2.242968e+06   \n",
      "mean   3.617996e+08  3.233541e+01     9.889330e-01    3.940358e+00   \n",
      "std    1.257530e+08  7.411118e+01     5.571145e-01    4.551701e-01   \n",
      "min    1.777602e+08 -5.970000e+02     0.000000e+00    0.000000e+00   \n",
      "25%    2.255402e+08 -3.062436e+00     1.000000e+00    4.000000e+00   \n",
      "50%    3.925612e+08  4.379763e+01     1.000000e+00    4.000000e+00   \n",
      "75%    4.333882e+08  8.145555e+01     1.000000e+00    4.000000e+00   \n",
      "max    8.546412e+08  3.199903e+02     3.300000e+01    4.000000e+00   \n",
      "\n",
      "                año           mes           dia          hora  \n",
      "count  2.242968e+06  2.242968e+06  2.242968e+06  2.242968e+06  \n",
      "mean   2.019914e+03  6.331461e+00  1.569222e+01  1.150346e+01  \n",
      "std    1.866976e+00  3.369501e+00  8.789557e+00  6.922906e+00  \n",
      "min    2.017000e+03  1.000000e+00  1.000000e+00  0.000000e+00  \n",
      "25%    2.018000e+03  4.000000e+00  8.000000e+00  6.000000e+00  \n",
      "50%    2.020000e+03  6.000000e+00  1.600000e+01  1.200000e+01  \n",
      "75%    2.022000e+03  9.000000e+00  2.300000e+01  1.800000e+01  \n",
      "max    2.023000e+03  1.200000e+01  3.100000e+01  2.300000e+01  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carga del archivo CSV\n",
    "ruta_archivo = 'nuevo_archivo_final_dataset_con_subestacion.csv'\n",
    "df = pd.read_csv(ruta_archivo)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para una rápida exploración\n",
    "print(df.head())\n",
    "\n",
    "# Ver la información del DataFrame para conocer los tipos de datos\n",
    "print(df.info())\n",
    "\n",
    "# Mostrar estadísticas descriptivas de las columnas numéricas\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3938effa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                    0\n",
      "fecha                 0\n",
      "consumo               0\n",
      "flap_de_calidad       0\n",
      "promedio_horas        0\n",
      "nombre_interruptor    0\n",
      "año                   0\n",
      "mes                   0\n",
      "dia                   0\n",
      "hora                  0\n",
      "sub_estacion          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores faltantes\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Manejar valores faltantes (por ejemplo, eliminar filas con datos faltantes o llenar con un valor)\n",
    "df = df.dropna()  # Elimina filas con valores faltantes\n",
    "\n",
    "# Convertir columnas categóricas a numéricas utilizando encoding\n",
    "# Por ejemplo, si hay una columna llamada 'nombre_interruptor' que es categórica:\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['nombre_interruptor'] = encoder.fit_transform(df['nombre_interruptor'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44725ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seleccionar características (X) y etiquetas (y)\n",
    "X = df.drop(['consumo'], axis=1)  # Ajusta según la variable objetivo\n",
    "y = df['consumo']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0b9542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Regresión lineal...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2022-09-02 22:00:00-0400'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nombre, modelo \u001b[38;5;129;01min\u001b[39;00m modelos\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Predicción en conjunto de prueba\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2022-09-02 22:00:00-0400'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# Definir modelos a entrenar\n",
    "modelos = {\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Bosque aleatorio': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "resultados = {}\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicción en conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Evaluación del modelo\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Si trabajas con un problema de clasificación, podrías usar las métricas siguientes:\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # precision = precision_score(y_test, y_pred)\n",
    "    # recall = recall_score(y_test, y_pred)\n",
    "    # f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\\n\")\n",
    "    \n",
    "    # Si trabajas con un problema de clasificación:\n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Precision: {precision:.4f}\")\n",
    "    # print(f\"Recall: {recall:.4f}\")\n",
    "    # print(f\"F1-score: {f1:.4f}\\n\")\n",
    "    \n",
    "    resultados[nombre] = (mae, mse, r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaaa3c16",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Separar los componentes de la columna 'fecha' en columnas de año, mes, día y hora\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maño\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfecha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39myear\n\u001b[0;32m     12\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m     13\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdía\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:512\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 512\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "ruta_archivo = 'nuevo_archivo_final_dataset_con_subestacion.csv'\n",
    "df = pd.read_csv(ruta_archivo)\n",
    "\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "\n",
    "# Separar los componentes de la columna 'fecha' en columnas de año, mes, día y hora\n",
    "df['año'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['día'] = df['fecha'].dt.day\n",
    "df['hora'] = df['fecha'].dt.hour\n",
    "\n",
    "# Eliminar la columna 'fecha' original si ya no es necesaria\n",
    "df = df.drop('fecha', axis=1)\n",
    "\n",
    "# Realizar otras conversiones de datos si es necesario\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Codificar la columna 'nombre_interruptor' si es categórica\n",
    "encoder = LabelEncoder()\n",
    "df['nombre_interruptor'] = encoder.fit_transform(df['nombre_interruptor'])\n",
    "\n",
    "# Convertir otras columnas categóricas si es necesario\n",
    "\n",
    "# Verificar datos faltantes\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Manejar valores faltantes (por ejemplo, eliminar filas con datos faltantes o rellenar con un valor)\n",
    "df = df.dropna()  # Eliminar filas con valores faltantes\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seleccionar características (X) y etiquetas (y)\n",
    "X = df.drop('consumo', axis=1)  # Ajusta según la variable objetivo\n",
    "y = df['consumo']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ahora puedes proceder con el entrenamiento y evaluación de los modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929789a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros registros de la columna 'fecha':\n",
      "0    2019-02-01 00:00:00-0300\n",
      "1    2019-02-01 00:00:00-0300\n",
      "2    2019-02-01 00:00:00-0300\n",
      "3    2019-02-01 00:00:00-0300\n",
      "4    2019-02-01 00:00:00-0300\n",
      "Name: fecha, dtype: object\n",
      "\n",
      "Columna 'fecha' convertida a tipo datetime.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Separar los componentes de la columna 'fecha' en columnas de año, mes, día y hora\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maño\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfecha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241m.\u001b[39myear\n\u001b[0;32m     26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdía\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:512\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[1;32m--> 512\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "ruta_archivo = 'nuevo_archivo_final_dataset_con_subestacion.csv'\n",
    "df = pd.read_csv(ruta_archivo)\n",
    "\n",
    "# Verificar los primeros registros de la columna 'fecha' para confirmar su formato\n",
    "print(\"Primeros registros de la columna 'fecha':\")\n",
    "print(df['fecha'].head())\n",
    "\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "try:\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')\n",
    "    print(\"\\nColumna 'fecha' convertida a tipo datetime.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nError al convertir 'fecha' a tipo datetime: {e}\")\n",
    "\n",
    "# Verificar si hay valores nulos en la columna 'fecha' después de la conversión\n",
    "if df['fecha'].isnull().sum() > 0:\n",
    "    print(\"\\nSe encontraron valores nulos en la columna 'fecha' después de la conversión.\")\n",
    "    # Manejar valores nulos (por ejemplo, eliminarlos o rellenarlos con un valor predeterminado)\n",
    "    df = df.dropna(subset=['fecha'])\n",
    "\n",
    "# Separar los componentes de la columna 'fecha' en columnas de año, mes, día y hora\n",
    "df['año'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['día'] = df['fecha'].dt.day\n",
    "df['hora'] = df['fecha'].dt.hour\n",
    "\n",
    "# Eliminar la columna 'fecha' original si ya no es necesaria\n",
    "df = df.drop('fecha', axis=1)\n",
    "\n",
    "# Imprimir los primeros registros para verificar la transformación\n",
    "print(\"\\nPrimeros registros después de separar 'fecha' en 'año', 'mes', 'día' y 'hora':\")\n",
    "print(df.head())\n",
    "\n",
    "# Continúa con el preprocesamiento de los datos y la implementación de los modelos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b0e134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeros registros después de separar 'fecha' en 'año', 'mes', 'día' y 'hora':\n",
      "          id     consumo  flap_de_calidad  promedio_horas  \\\n",
      "0  177760211  -51.381349                1               4   \n",
      "1  395102211 -171.906310                1               4   \n",
      "2  395684211   94.762790                1               4   \n",
      "3  397670211   47.114733                1               4   \n",
      "4  397693211   59.313975                1               4   \n",
      "\n",
      "          nombre_interruptor   año  mes  dia  hora sub_estacion  día  \n",
      "0    AJAHUEL   110  H1     P  2019    2    1     3      AJAHUEL    1  \n",
      "1  BUIN      110  HT1    MTP  2019    2    1     3         BUIN    1  \n",
      "2    BUIN      110  H2     P  2019    2    1     3         BUIN    1  \n",
      "3    LOSALME   110  H1     P  2019    2    1     3      LOSALME    1  \n",
      "4    LOSALME   110  H3     P  2019    2    1     3      LOSALME    1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "ruta_archivo = 'nuevo_archivo_final_dataset_con_subestacion.csv'\n",
    "df = pd.read_csv(ruta_archivo)\n",
    "\n",
    "# Convertir la columna 'fecha' a tipo datetime, manejando la zona horaria\n",
    "df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce', utc=True)\n",
    "\n",
    "# Convertir la zona horaria a UTC (hora estándar coordinada) y eliminarla\n",
    "df['fecha'] = df['fecha'].dt.tz_convert('UTC')\n",
    "\n",
    "# Separar los componentes de la columna 'fecha' en columnas de año, mes, día y hora\n",
    "df['año'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['día'] = df['fecha'].dt.day\n",
    "df['hora'] = df['fecha'].dt.hour\n",
    "\n",
    "# Eliminar la columna 'fecha' original si ya no es necesaria\n",
    "df = df.drop('fecha', axis=1)\n",
    "\n",
    "# Imprimir los primeros registros para verificar la transformación\n",
    "print(\"\\nPrimeros registros después de separar 'fecha' en 'año', 'mes', 'día' y 'hora':\")\n",
    "print(df.head())\n",
    "\n",
    "# Continúa con el preprocesamiento de los datos y la implementación de los modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bdd0093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Regresión lineal...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2022-09-02 22:00:00-0400'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nombre, modelo \u001b[38;5;129;01min\u001b[39;00m modelos\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Predicción en conjunto de prueba\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:648\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    644\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    646\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 648\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    653\u001b[0m     sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    654\u001b[0m )\n\u001b[0;32m    656\u001b[0m X, y, X_offset, y_offset, X_scale \u001b[38;5;241m=\u001b[39m _preprocess_data(\n\u001b[0;32m    657\u001b[0m     X,\n\u001b[0;32m    658\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    661\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m    662\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2022-09-02 22:00:00-0400'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# Definir modelos a entrenar\n",
    "modelos = {\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Bosque aleatorio': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "resultados = {}\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicción en conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Evaluación del modelo\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Si trabajas con un problema de clasificación, podrías usar las métricas siguientes:\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # precision = precision_score(y_test, y_pred)\n",
    "    # recall = recall_score(y_test, y_pred)\n",
    "    # f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\\n\")\n",
    "    \n",
    "    # Si trabajas con un problema de clasificación:\n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Precision: {precision:.4f}\")\n",
    "    # print(f\"Recall: {recall:.4f}\")\n",
    "    # print(f\"F1-score: {f1:.4f}\\n\")\n",
    "    \n",
    "    resultados[nombre] = (mae, mse, r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a60b0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'columna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'columna'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumna\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumna\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'columna'"
     ]
    }
   ],
   "source": [
    "df['columna'] = pd.to_numeric(df['columna'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af1fd3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                     fecha     consumo  flap_de_calidad  \\\n",
      "0  177760211  2019-02-01 00:00:00-0300  -51.381349                1   \n",
      "1  395102211  2019-02-01 00:00:00-0300 -171.906310                1   \n",
      "2  395684211  2019-02-01 00:00:00-0300   94.762790                1   \n",
      "3  397670211  2019-02-01 00:00:00-0300   47.114733                1   \n",
      "4  397693211  2019-02-01 00:00:00-0300   59.313975                1   \n",
      "\n",
      "   promedio_horas         nombre_interruptor   año  mes  dia  hora  \\\n",
      "0               4    AJAHUEL   110  H1     P  2019    2    1     0   \n",
      "1               4  BUIN      110  HT1    MTP  2019    2    1     0   \n",
      "2               4    BUIN      110  H2     P  2019    2    1     0   \n",
      "3               4    LOSALME   110  H1     P  2019    2    1     0   \n",
      "4               4    LOSALME   110  H3     P  2019    2    1     0   \n",
      "\n",
      "  sub_estacion  \n",
      "0      AJAHUEL  \n",
      "1         BUIN  \n",
      "2         BUIN  \n",
      "3      LOSALME  \n",
      "4      LOSALME  \n",
      "Nombres de las columnas: Index(['id', 'fecha', 'consumo', 'flap_de_calidad', 'promedio_horas',\n",
      "       'nombre_interruptor', 'año', 'mes', 'dia', 'hora', 'sub_estacion'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta del archivo CSV\n",
    "ruta_archivo = 'nuevo_archivo_final_dataset_con_subestacion.csv'\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = pd.read_csv(ruta_archivo)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Mostrar los nombres de las columnas\n",
    "print(\"Nombres de las columnas:\", df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda2d026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes en cada columna:\n",
      "id                    0\n",
      "fecha                 0\n",
      "consumo               0\n",
      "flap_de_calidad       0\n",
      "promedio_horas        0\n",
      "nombre_interruptor    0\n",
      "año                   0\n",
      "mes                   0\n",
      "dia                   0\n",
      "hora                  0\n",
      "sub_estacion          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores faltantes en cada columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Puedes decidir cómo manejar los valores faltantes, por ejemplo, eliminarlos\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2e1c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce', utc=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "015d33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la zona horaria a UTC y eliminarla si es necesario\n",
    "df['fecha'] = df['fecha'].dt.tz_convert('UTC')\n",
    "\n",
    "# Separar los componentes de fecha\n",
    "df['año'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['día'] = df['fecha'].dt.day\n",
    "df['hora'] = df['fecha'].dt.hour\n",
    "\n",
    "# Eliminar la columna `fecha` original si ya no es necesaria\n",
    "df = df.drop('fecha', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b24bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convertir columnas categóricas a numéricas\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Convertir la columna 'flap_de_calidad'\n",
    "df['flap_de_calidad'] = encoder.fit_transform(df['flap_de_calidad'])\n",
    "\n",
    "# Convertir la columna 'nombre_interruptor'\n",
    "df['nombre_interruptor'] = encoder.fit_transform(df['nombre_interruptor'])\n",
    "\n",
    "# Convertir la columna 'sub_estacion'\n",
    "df['sub_estacion'] = encoder.fit_transform(df['sub_estacion'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86663660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 56.0399\n",
      "MSE: 5368.0187\n",
      "R2: 0.0152\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Características (X) y etiquetas (y)\n",
    "X = df.drop('consumo', axis=1)  # Ajusta la variable objetivo\n",
    "y = df['consumo']\n",
    "\n",
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenamiento y evaluación de modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Crear modelo de regresión lineal\n",
    "modelo = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0b9c7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando Regresión lineal...\n",
      "Regresión lineal:\n",
      "MAE: 56.0399\n",
      "MSE: 5368.0187\n",
      "R2: 0.0152\n",
      "\n",
      "Entrenando Bosque aleatorio...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    781\u001b[0m job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:650\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[1;34m(predict, X, out, lock)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[38;5;124;03mThis is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \n\u001b[0;32m    647\u001b[0m \u001b[38;5;124;03mIt can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;124;03mcomplains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 650\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:427\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    426\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[1;32m--> 427\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    428\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[22], line 20\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Predicción en conjunto de prueba\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluación del modelo\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:994\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    993\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[1;32m--> 994\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    999\u001b[0m y_hat \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1069\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop_call\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m-> 1069\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_managed_backend:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:83\u001b[0m, in \u001b[0;36mParallelBackendBase.stop_call\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call-back method called at the beginning of a Parallel call\"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstop_call\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call-back method called at the end of a Parallel call\"\"\"\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\executing\\executing.py:317\u001b[0m, in \u001b[0;36mSource.executing\u001b[1;34m(cls, frame_or_tb)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 317\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mexecuting_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: (<code object <module> at 0x0000023CA787C5B0, file \"C:\\Users\\YASITCOMPUTER\\AppData\\Local\\Temp\\ipykernel_13924\\2252697105.py\", line 1>, 2459531986352, 50)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2057\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2056\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2057\u001b[0m         stb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_offset\u001b[49m\n\u001b[0;32m   2059\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m tb\n\u001b[1;32m-> 1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    797\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(etype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m    798\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    849\u001b[0m options \u001b[38;5;241m=\u001b[39m stack_data\u001b[38;5;241m.\u001b[39mOptions(\n\u001b[0;32m    850\u001b[0m     before\u001b[38;5;241m=\u001b[39mbefore,\n\u001b[0;32m    851\u001b[0m     after\u001b[38;5;241m=\u001b[39mafter,\n\u001b[0;32m    852\u001b[0m     pygments_formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[0;32m    853\u001b[0m )\n\u001b[1;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stack_data\\core.py:565\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[1;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m frame\u001b[38;5;241m.\u001b[39mf_code, lineno\n\u001b[1;32m--> 565\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m collapse_repeated(\n\u001b[0;32m    566\u001b[0m     stack,\n\u001b[0;32m    567\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mmapper,\n\u001b[0;32m    568\u001b[0m     collapser\u001b[38;5;241m=\u001b[39mRepeatedFrames,\n\u001b[0;32m    569\u001b[0m     key\u001b[38;5;241m=\u001b[39m_frame_key,\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stack_data\\utils.py:84\u001b[0m, in \u001b[0;36mcollapse_repeated\u001b[1;34m(lst, collapser, mapper, key)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_highlighted:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(mapper, original_group)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stack_data\\core.py:555\u001b[0m, in \u001b[0;36mFrameInfo.stack_data.<locals>.mapper\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmapper\u001b[39m(f):\n\u001b[1;32m--> 555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\stack_data\\core.py:520\u001b[0m, in \u001b[0;36mFrameInfo.__init__\u001b[1;34m(self, frame_or_tb, options)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    517\u001b[0m         frame_or_tb: Union[FrameType, TracebackType],\n\u001b[0;32m    518\u001b[0m         options: Optional[Options] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    519\u001b[0m ):\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecuting \u001b[38;5;241m=\u001b[39m \u001b[43mSource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecuting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m     frame, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno \u001b[38;5;241m=\u001b[39m frame_and_lineno(frame_or_tb)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\executing\\executing.py:369\u001b[0m, in \u001b[0;36mSource.executing\u001b[1;34m(cls, frame_or_tb)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m source, node, stmts, decorator\n\u001b[1;32m--> 369\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    370\u001b[0m executing_cache[key] \u001b[38;5;241m=\u001b[39m args\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\executing\\executing.py:326\u001b[0m, in \u001b[0;36mSource.executing.<locals>.find\u001b[1;34m(source, retry_cache)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stmts:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_ipython_cell_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m stmt \u001b[38;5;129;01min\u001b[39;00m stmts:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\executing\\executing.py:1086\u001b[0m, in \u001b[0;36mis_ipython_cell_code\u001b[1;34m(code_obj)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_ipython_cell_code\u001b[39m(code_obj):\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m-> 1086\u001b[0m         \u001b[43mis_ipython_cell_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mco_filename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m         is_ipython_cell_code_name(code_obj\u001b[38;5;241m.\u001b[39mco_name)\n\u001b[0;32m   1088\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\executing\\executing.py:1081\u001b[0m, in \u001b[0;36mis_ipython_cell_filename\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_ipython_cell_filename\u001b[39m(filename):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<ipython-input-|[/\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m]ipykernel_\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+[/\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:200\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;124;03ma Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\re.py:293\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cache[\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m, pattern, flags]\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2078\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2075\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_showtraceback(etype, value, stb)\n\u001b[0;32m   2077\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m-> 2078\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2014\u001b[0m, in \u001b[0;36mInteractiveShell.get_exception_only\u001b[1;34m(self, exc_tuple)\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2010\u001b[0m \u001b[38;5;124;03mReturn as a string (ending with a newline) the exception that\u001b[39;00m\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;124;03mjust occurred, without any traceback.\u001b[39;00m\n\u001b[0;32m   2012\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2013\u001b[0m etype, value, tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_exc_info(exc_tuple)\n\u001b[1;32m-> 2014\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2015\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(msg)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\traceback.py:155\u001b[0m, in \u001b[0;36mformat_exception_only\u001b[1;34m(exc, value)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m _sentinel:\n\u001b[0;32m    154\u001b[0m     value \u001b[38;5;241m=\u001b[39m exc\n\u001b[1;32m--> 155\u001b[0m te \u001b[38;5;241m=\u001b[39m \u001b[43mTracebackException\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(te\u001b[38;5;241m.\u001b[39mformat_exception_only())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\traceback.py:552\u001b[0m, in \u001b[0;36mTracebackException.__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, _seen)\u001b[0m\n\u001b[0;32m    549\u001b[0m     need_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (e \u001b[38;5;129;01mand\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__context__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m need_context \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mid\u001b[39m(e\u001b[38;5;241m.\u001b[39m__context__) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _seen):\n\u001b[1;32m--> 552\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43mTracebackException\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__context__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__traceback__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_seen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_seen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    561\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\traceback.py:502\u001b[0m, in \u001b[0;36mTracebackException.__init__\u001b[1;34m(self, exc_type, exc_value, exc_traceback, limit, lookup_lines, capture_locals, compact, _seen)\u001b[0m\n\u001b[0;32m    499\u001b[0m _seen\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exc_value))\n\u001b[0;32m    501\u001b[0m \u001b[38;5;66;03m# TODO: locals.\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwalk_tb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_traceback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_lines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlookup_lines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_locals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_locals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexc_type \u001b[38;5;241m=\u001b[39m exc_type\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Capture now to permit freeing resources: only complication is in the\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# unofficial API _format_final_exc_line\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\traceback.py:383\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m--> 383\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mline\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\traceback.py:306\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineno \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line \u001b[38;5;241m=\u001b[39m \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_line\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetline\u001b[39m(filename, lineno, module_globals\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     lines \u001b[38;5;241m=\u001b[39m \u001b[43mgetlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(lines):\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m lines[lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cache[filename][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdatecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_globals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\linecache.py:93\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     91\u001b[0m fullname \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     basename \u001b[38;5;241m=\u001b[39m filename\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "\n",
    "# Definir modelos a entrenar\n",
    "modelos = {\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Bosque aleatorio': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "resultados = {}\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicción en conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Evaluación del modelo\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Si trabajas con un problema de clasificación, podrías usar las métricas siguientes:\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # precision = precision_score(y_test, y_pred)\n",
    "    # recall = recall_score(y_test, y_pred)\n",
    "    # f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(f\"{nombre}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\\n\")\n",
    "    \n",
    "    # Si trabajas con un problema de clasificación:\n",
    "    # print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    # print(f\"Precision: {precision:.4f}\")\n",
    "    # print(f\"Recall: {recall:.4f}\")\n",
    "    # print(f\"F1-score: {f1:.4f}\\n\")\n",
    "    \n",
    "    resultados[nombre] = (mae, mse, r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supongamos que df es tu DataFrame y 'consumo' es la columna objetivo\n",
    "X = df.drop(columns=['consumo'])\n",
    "y = df['consumo']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9217440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Diccionario con los modelos a entrenar\n",
    "modelos = {\n",
    "    'Regresión Lineal': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'K-NN': KNeighborsRegressor(),\n",
    "    'Árbol de Decisión': DecisionTreeRegressor()\n",
    "}\n",
    "\n",
    "# Entrenamiento y evaluación de los modelos\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular MAE y MSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Si se trata de un problema de clasificación\n",
    "    # Convertir regresión a clasificación dividiendo `y_test` y `y_pred` en categorías\n",
    "    # Esto solo es un ejemplo, debes ajustar los umbrales o categorías según tu caso\n",
    "    umbral = y_test.mean()  # puedes elegir otro umbral\n",
    "    y_test_clasificacion = (y_test > umbral).astype(int)\n",
    "    y_pred_clasificacion = (y_pred > umbral).astype(int)\n",
    "    \n",
    "    # Calcular Accuracy, Precision, Recall, y F1\n",
    "    accuracy = accuracy_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    precision = precision_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    recall = recall_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    f1 = f1_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    \n",
    "    # Mostrar los resultados\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b01fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Diccionario con los modelos a entrenar\n",
    "modelos = {\n",
    "    'Regresión Lineal': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(),\n",
    "    'K-NN': KNeighborsRegressor(),\n",
    "    'Árbol de Decisión': DecisionTreeRegressor()\n",
    "}\n",
    "\n",
    "# Entrenamiento y evaluación de los modelos\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Realizar predicciones en el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular MAE y MSE\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    # Si se trata de un problema de clasificación\n",
    "    # Convertir regresión a clasificación dividiendo `y_test` y `y_pred` en categorías\n",
    "    # Esto solo es un ejemplo, debes ajustar los umbrales o categorías según tu caso\n",
    "    umbral = y_test.mean()  # puedes elegir otro umbral\n",
    "    y_test_clasificacion = (y_test > umbral).astype(int)\n",
    "    y_pred_clasificacion = (y_pred > umbral).astype(int)\n",
    "    \n",
    "    # Calcular Accuracy, Precision, Recall, y F1\n",
    "    accuracy = accuracy_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    precision = precision_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    recall = recall_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    f1 = f1_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    \n",
    "    # Mostrar los resultados\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33539529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Aquí asume que tus datos ya están divididos en conjuntos de entrenamiento y prueba\n",
    "# Asegúrate de tener definidas las variables X_train, y_train, X_test, y_test.\n",
    "\n",
    "# Crear diccionario de modelos\n",
    "modelos = {\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Árbol de decisión': DecisionTreeRegressor(),\n",
    "    'Bosque aleatorio': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Inicializar un diccionario para guardar las métricas\n",
    "metricas = {}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Convertir las predicciones y_test a etiquetas de clase (clasificación)\n",
    "    # Vamos a usar un umbral para convertir las predicciones en 0 o 1\n",
    "    umbral = np.median(y_test)\n",
    "    y_test_clasificacion = (y_test > umbral).astype(int)\n",
    "    y_pred_clasificacion = (y_pred > umbral).astype(int)\n",
    "    \n",
    "    # Calcular las métricas de clasificación\n",
    "    accuracy = accuracy_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    precision = precision_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    recall = recall_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    f1 = f1_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    \n",
    "    # Almacenar las métricas en el diccionario\n",
    "    metricas[nombre] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1\n",
    "    }\n",
    "    \n",
    "    # Mostrar las métricas\n",
    "    print(f\"\\nResultados de {nombre}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Ahora puedes usar el diccionario metricas para acceder a las métricas de cada modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4197bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Cargar los datos desde un archivo CSV\n",
    "# Cambia 'ruta_archivo.csv' por la ruta de tu archivo CSV\n",
    "df = pd.read_csv('ruta_archivo.csv')\n",
    "\n",
    "# Procesamiento de datos\n",
    "# Convierte la columna 'fecha' a tipo datetime si es necesario\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "\n",
    "# Separar la columna de fecha en año, mes, día, hora\n",
    "df['año'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['día'] = df['fecha'].dt.day\n",
    "df['hora'] = df['fecha'].dt.hour\n",
    "\n",
    "# Eliminar la columna 'fecha' si ya no es necesaria\n",
    "df = df.drop('fecha', axis=1)\n",
    "\n",
    "# Asegúrate de que no haya valores nulos en tus datos\n",
    "df = df.dropna()\n",
    "\n",
    "# Separar las características y la variable objetivo\n",
    "X = df.drop('consumo', axis=1)  # Características (todas las columnas excepto 'consumo')\n",
    "y = df['consumo']  # Variable objetivo (columna 'consumo')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear diccionario de modelos\n",
    "modelos = {\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Árbol de decisión': DecisionTreeRegressor(),\n",
    "    'Bosque aleatorio': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Inicializar un diccionario para guardar las métricas\n",
    "metricas = {}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Convertir las predicciones y_test a etiquetas de clase (clasificación)\n",
    "    # Vamos a usar un umbral para convertir las predicciones en 0 o 1\n",
    "    umbral = np.median(y_test)\n",
    "    y_test_clasificacion = (y_test > umbral).astype(int)\n",
    "    y_pred_clasificacion = (y_pred > umbral).astype(int)\n",
    "    \n",
    "    # Calcular las métricas de clasificación\n",
    "    accuracy = accuracy_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    precision = precision_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    recall = recall_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    f1 = f1_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    \n",
    "    # Almacenar las métricas en el diccionario\n",
    "    metricas[nombre] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1\n",
    "    }\n",
    "    \n",
    "    # Mostrar las métricas\n",
    "    print(f\"\\nResultados de {nombre}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Los resultados se muestran en la consola\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc93f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Cargar los datos desde un archivo CSV\n",
    "# Cambia 'ruta_archivo.csv' por la ruta de tu archivo CSV\n",
    "df = pd.read_csv('nuevo_archivo_final_dataset_con_subestacion.csv')\n",
    "\n",
    "# Procesamiento de datos\n",
    "# Convierte la columna 'fecha' a tipo datetime si es necesario\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "\n",
    "# Separar la columna de fecha en año, mes, día, hora\n",
    "df['año'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['día'] = df['fecha'].dt.day\n",
    "df['hora'] = df['fecha'].dt.hour\n",
    "\n",
    "# Eliminar la columna 'fecha' si ya no es necesaria\n",
    "df = df.drop('fecha', axis=1)\n",
    "\n",
    "# Asegúrate de que no haya valores nulos en tus datos\n",
    "df = df.dropna()\n",
    "\n",
    "# Separar las características y la variable objetivo\n",
    "X = df.drop('consumo', axis=1)  # Características (todas las columnas excepto 'consumo')\n",
    "y = df['consumo']  # Variable objetivo (columna 'consumo')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear diccionario de modelos\n",
    "modelos = {\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Árbol de decisión': DecisionTreeRegressor(),\n",
    "    'Bosque aleatorio': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Inicializar un diccionario para guardar las métricas\n",
    "metricas = {}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Convertir las predicciones y_test a etiquetas de clase (clasificación)\n",
    "    # Vamos a usar un umbral para convertir las predicciones en 0 o 1\n",
    "    umbral = np.median(y_test)\n",
    "    y_test_clasificacion = (y_test > umbral).astype(int)\n",
    "    y_pred_clasificacion = (y_pred > umbral).astype(int)\n",
    "    \n",
    "    # Calcular las métricas de clasificación\n",
    "    accuracy = accuracy_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    precision = precision_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    recall = recall_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    f1 = f1_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    \n",
    "    # Almacenar las métricas en el diccionario\n",
    "    metricas[nombre] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1\n",
    "    }\n",
    "    \n",
    "    # Mostrar las métricas\n",
    "    print(f\"\\nResultados de {nombre}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Los resultados se muestran en la consola\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Cargar los datos desde un archivo CSV\n",
    "df = pd.read_csv('nuevo_archivo_final_dataset_con_subestacion.csv')\n",
    "\n",
    "# Procesamiento de datos\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "\n",
    "# Separar la columna de fecha en año, mes, día, hora\n",
    "df['año'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['día'] = df['fecha'].dt.day\n",
    "df['hora'] = df['fecha'].dt.hour\n",
    "\n",
    "# Eliminar la columna 'fecha' si ya no es necesaria\n",
    "df = df.drop('fecha', axis=1)\n",
    "\n",
    "# Asegúrate de que no haya valores nulos en tus datos\n",
    "df = df.dropna()\n",
    "\n",
    "# Separar las características y la variable objetivo\n",
    "X = df.drop('consumo', axis=1)  # Características (todas las columnas excepto 'consumo')\n",
    "y = df['consumo']  # Variable objetivo (columna 'consumo')\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear diccionario de modelos\n",
    "modelos = {\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Árbol de decisión': DecisionTreeRegressor(),\n",
    "    'Bosque aleatorio': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Inicializar un diccionario para guardar las métricas\n",
    "metricas = {}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"Entrenando {nombre}...\")\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Convertir las predicciones y_test a etiquetas de clase (clasificación)\n",
    "    # Vamos a usar un umbral para convertir las predicciones en 0 o 1\n",
    "    umbral = np.median(y_test)\n",
    "    y_test_clasificacion = (y_test > umbral).astype(int)\n",
    "    y_pred_clasificacion = (y_pred > umbral).astype(int)\n",
    "    \n",
    "    # Calcular las métricas de clasificación\n",
    "    accuracy = accuracy_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    precision = precision_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    recall = recall_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    f1 = f1_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    \n",
    "    # Almacenar las métricas en el diccionario\n",
    "    metricas[nombre] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1\n",
    "    }\n",
    "    \n",
    "    # Mostrar las métricas\n",
    "    print(f\"\\nResultados de {nombre}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1: {f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Los resultados se mostrarán en la consola\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50570d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Cargar los datos desde un archivo CSV\n",
    "df = pd.read_csv('nuevo_archivo_final_dataset_con_subestacion.csv')\n",
    "\n",
    "# Procesamiento de datos\n",
    "# Convertir la columna 'fecha' a tipo datetime\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "\n",
    "# Separar la columna de fecha en año, mes, día, hora\n",
    "df['año'] = df['fecha'].dt.year\n",
    "df['mes'] = df['fecha'].dt.month\n",
    "df['día'] = df['fecha'].dt.day\n",
    "df['hora'] = df['fecha'].dt.hour\n",
    "\n",
    "# Eliminar la columna 'fecha' ya que se divide en otras columnas\n",
    "df = df.drop('fecha', axis=1)\n",
    "\n",
    "# Eliminar valores nulos\n",
    "df = df.dropna()\n",
    "\n",
    "# Codificar la columna 'nombre_interruptor' si existe\n",
    "if 'nombre_interruptor' in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    df['nombre_interruptor'] = le.fit_transform(df['nombre_interruptor'])\n",
    "\n",
    "# Separar características y la variable objetivo\n",
    "X = df.drop('consumo', axis=1)\n",
    "y = df['consumo']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear diccionario de modelos\n",
    "modelos = {\n",
    "    'Regresión lineal': LinearRegression(),\n",
    "    'Árbol de decisión': DecisionTreeRegressor(),\n",
    "    'Bosque aleatorio': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Inicializar un diccionario para guardar las métricas\n",
    "metricas = {}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\nEntrenando modelo: {nombre}\")\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones en el conjunto de prueba\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Calcular métricas de regresión\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Calcular métricas de clasificación\n",
    "    umbral = np.median(y_test)  # Umbral para convertir valores a clasificación\n",
    "    y_test_clasificacion = (y_test > umbral).astype(int)\n",
    "    y_pred_clasificacion = (y_pred > umbral).astype(int)\n",
    "    \n",
    "    # Calcular métricas de clasificación\n",
    "    accuracy = accuracy_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    precision = precision_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    recall = recall_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    f1 = f1_score(y_test_clasificacion, y_pred_clasificacion)\n",
    "    \n",
    "    # Almacenar las métricas en el diccionario\n",
    "    metricas[nombre] = {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1\n",
    "    }\n",
    "    \n",
    "    # Imprimir las métricas del modelo\n",
    "    print(f\"Resultados de {nombre}:\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1: {f1:.4f}\")\n",
    "\n",
    "# Los resultados se mostrarán al finalizar cada modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4683a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
